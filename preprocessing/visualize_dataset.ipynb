{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python39\\lib\\site-packages (from requests) (2.1.1)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: urllib3, certifi, idna, requests\n",
      "Successfully installed certifi-2022.12.7 idna-3.4 requests-2.28.1 urllib3-1.26.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"multi_label_train.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/multi_label_train_v0.4.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(\u001b[39m\"\u001b[39;49m\u001b[39m../data/multi_label_train_v0.4.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[1;32m--> 190\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    191\u001b[0m     filepath_or_buffer,\n\u001b[0;32m    192\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    193\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    194\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    195\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    196\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/multi_label_train_v0.4.pkl'"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/multi_label_train_v0.4.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- Incident vs place heatmap\n",
    "- Incident vs incident\n",
    "- Top 10 incident/place\n",
    "- Subsample and maintain distribution\n",
    "- Rename images according to key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"incidents_list\"] == \"unknown\") | (df[\"places_list\"] == \"unknown\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts of each incident and place by splitting the string with \", \"\n",
    "# and then counting the number of times each incident or place appears\n",
    "incidents = df[\"incidents_list\"].str.split(\", \").explode().value_counts()[1:]\n",
    "places = df[\"places_list\"].str.split(\", \").explode().value_counts()[1:]\n",
    "\n",
    "# Only show the top 25 incidents and places\n",
    "incidents = incidents[:25]\n",
    "places = places[:25]\n",
    "\n",
    "# Plot incidents and places as a bar chart with a large font size\n",
    "fig, ax = plt.subplots(1, 2, figsize=(22, 10))\n",
    "sns.barplot(x=incidents.values, y=incidents.index, ax=ax[0], palette=\"Blues_d\")\n",
    "sns.barplot(x=places.values, y=places.index, ax=ax[1], palette=\"Blues_d\")\n",
    "ax[0].set_title(\"Top 15 Incidents\", fontsize=20)\n",
    "ax[1].set_title(\"Top 15 Places\", fontsize=20)\n",
    "# Make the font size of the x and y axis labels larger\n",
    "ax[0].tick_params(labelsize=12)\n",
    "ax[1].tick_params(labelsize=12)\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Number of known incidents\"] = df.incidents.apply(lambda x: len({k: v for k, v in dict(x).items() if v == 1}))\n",
    "df[\"Number of unknown incidents\"] = df.incidents.apply(lambda x: len({k: v for k, v in dict(x).items() if v == 0}))\n",
    "\n",
    "df[\"Number of known places\"] = df.places.apply(lambda x: len({k: v for k, v in dict(x).items() if v == 1}))\n",
    "df[\"Number of unknown places\"] = df.places.apply(lambda x: len({k: v for k, v in dict(x).items() if v == 0}))\n",
    "\n",
    "total_known_incidents = df[\"Number of known incidents\"].sum()\n",
    "total_unknown_incidents = df[\"Number of unknown incidents\"].sum()\n",
    "\n",
    "total_known_places = df[\"Number of known places\"].sum()\n",
    "total_unknown_places = df[\"Number of unknown places\"].sum()\n",
    "\n",
    "print(\"Total known incidents: \", total_known_incidents)\n",
    "print(\"Total unknown incidents: \", total_unknown_incidents)\n",
    "\n",
    "print(\"Total known places: \", total_known_places)\n",
    "print(\"Total unknown places: \", total_unknown_places)\n",
    "\n",
    "df[(df[\"valid_image\"] == False) & (df[\"downloadable\"] == True) & (df[\"image_id\"] != \"-1\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_label_counts = df[\"Number of known incidents\"].value_counts()\n",
    "place_label_counts = df[\"Number of known places\"].value_counts()\n",
    "\n",
    "#Â Replace each index with number and %%!\n",
    "incident_label_counts.index = [\"Unknown\" if i == 0 else f\"{i} label(s)\" for i in incident_label_counts.index]\n",
    "incident_label_counts\n",
    "\n",
    "place_label_counts.index = [\"Unknown\" if i == 0 else f\"{i} label(s)\" for i in place_label_counts.index]\n",
    "place_label_counts\n",
    "\n",
    "# Plot the number of images with each number of labels\n",
    "fig, ax = plt.subplots(1, 2, figsize=(22, 10))\n",
    "sns.barplot(x=incident_label_counts.index, y=incident_label_counts.values, ax=ax[0], palette=\"Blues_d\")\n",
    "sns.barplot(x=place_label_counts.index, y=place_label_counts.values, ax=ax[1], palette=\"Blues_d\")\n",
    "ax[0].set_title(\"Incidents positive-label distrution\", fontsize=20)\n",
    "ax[1].set_title(\"Places positive-label distribution\", fontsize=20)\n",
    "# Make the font size of the x and y axis labels larger\n",
    "ax[0].tick_params(labelsize=12)\n",
    "ax[1].tick_params(labelsize=12)\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = len(df)\n",
    "print(\"Total images: \", all_images)\n",
    "downloadable_images = len(df[df[\"downloadable\"] == True])\n",
    "print(\"Downloadable images: \", downloadable_images)\n",
    "valid_images = len(df[df[\"valid_image\"] == True])\n",
    "print(\"Valid images: \", valid_images)\n",
    "not_unknown_images = len(df[(df[\"Number of known incidents\"] != 0) & (df[\"Number of known places\"] != 0)])\n",
    "print(\"Images with known incidents and places: \", not_unknown_images)\n",
    "\n",
    "x_labels = [\"Total images\", \"Downloadable images\", \"Valid images\", \"Images with known incidents and places\"]\n",
    "y_values = [all_images, downloadable_images, valid_images, not_unknown_images]\n",
    "y_values = [val // 1000 for val in y_values]\n",
    "\n",
    "# Plot the number of images with each number of labels in \n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "sns.barplot(x=x_labels, y=y_values, ax=ax)\n",
    "ax.set_title(\"Image counts (in thousands)\", fontsize=20)\n",
    "# Make the font size of the x and y axis labels larger\n",
    "ax.tick_params(labelsize=12)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
